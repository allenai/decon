"""
Some internal helpers to read the internal files generated by the rust code. 
Think of this as a debugging tool/inspector 
"""

import glob
import json
import os
import struct
from collections import defaultdict

import yaml
from smart_open import open

# =====================================================
# =                  CONFIG PARSEY STUFF              =
# =====================================================


MAX_U64 = (1 << 64) - 1


def to_byte_size(n):
    assert isinstance(n, int)
    return max(1, (n.bit_length() + 7) // 8)


def compute_sig_size(n):
    n_choose_2 = (n * (n - 1)) // 2
    return max(1, (n_choose_2.bit_length() + 7) // 8)


def unpack_u64le(b):
    return struct.unpack("<Q", b)[0]


def read_intX(bytestring):
    result = 0
    for b in bytestring:
        result = (result << 8) | b
    return result


def get_sizes(config):
    config_data = yaml.safe_load(open(config, "r"))
    max_lines_per_path = config_data["max_lines_per_path"]
    num_docs = config_data["num_docs"]

    file_map_loc = os.path.join(config_data["working_dir"], "filemap.json.gz")
    file_map = json.loads(open(file_map_loc, "rb").read())

    path_size = to_byte_size(len(file_map["indices"]))
    line_size = to_byte_size(max_lines_per_path)
    sig_size = compute_sig_size(num_docs)

    return path_size, line_size, sig_size


# =====================================================
# =                  SIGNATURE READER                 =
# =====================================================


def read_all_sig_files(sig_dir, config):
    # Returns a list of (band_id, path_id, line_num, signature)

    files = glob.glob(os.path.join(sig_dir, "**/*.sig.bin"), recursive=True)
    all_data = []
    for f in files:
        band_id = os.path.basename(os.path.dirname(os.path.dirname(f))).split("_")[-1]
        for tup in read_signature_file(f, config):
            all_data.append((band_id,) + tup)
    return all_data


def read_signature_file(sig_file, config):
    # Returns a list of (path_id, line_num, signature)
    data = open(sig_file, "rb").read()

    path_size, line_size, sig_size = get_sizes(config)
    output = []
    for i in range(0, len(data), path_size + line_size + sig_size):
        chunk = data[i : i + path_size + line_size + sig_size]
        signature = read_intX(chunk[:sig_size])
        path_id = read_intX(chunk[sig_size : sig_size + path_size])
        line_id = read_intX(chunk[sig_size + path_size :])
        output.append((path_id, line_id, signature))
    return output


# =====================================================
# =                  READ EDGE STUFF                  =
# =====================================================


def read_singletons(singleton_file):
    data = open(singleton_file, "rb").read()
    singletons = {}
    for byte_start in range(0, len(data), 16):
        k = data[byte_start : byte_start + 8]
        v = data[byte_start + 8 : byte_start + 16]
        singletons[unpack_u64le(k)] = unpack_u64le(v)
    return singletons


def read_edge_file(edge_file, config):
    path_size, line_size, _ = get_sizes(config)
    data = open(edge_file, "rb").read()

    pairlen = path_size + line_size
    max_path = 1 << path_size - 1
    max_line = 1 << line_size - 1

    edges = []
    cur_group = []
    for i in range(0, len(data), path_size + line_size):
        chunk = data[i : i + path_size + line_size]
        path_id = read_intX(chunk[:path_size])
        line_id = read_intX(chunk[path_size:])

        if (path_id, line_id) == (max_path, max_line):
            edges.append(cur_group)
            cur_group = []
        else:
            cur_group.append((path_id, line_id))

    return edges


# =====================================================
# =                   READ CC STUFF                   =
# =====================================================


def read_cc_file(cc_file):
    data = open(cc_file, "rb").read()

    ccs = []
    cur_group = []
    for i in range(0, len(data), 16):
        l, r = data[i : i + 8], data[i + 8 : i + 16]
        x, y = unpack_u64le(l), unpack_u64le(r)
        if (x, y) == (MAX_U64, MAX_U64):
            ccs.append(cur_group)
            cur_group = []
        else:
            cur_group.append((x, y))
    return ccs


def read_kill_file(kill_file):
    data = open(kill_file, "rb").read()

    kill_dict = defaultdict(list)
    new_group = True
    group_id = None
    cur_lines = []
    for i in range(0, len(data), 8):
        x = unpack_u64le(data[i : i + 8])
        if new_group:
            group_id = x
            new_group = False
        elif x == MAX_U64:
            kill_dict[group_id].append(cur_lines)
            cur_lines = []
            new_group = True
        else:
            cur_lines.append(x)
    assert cur_lines == []
    return kill_dict


def read_anno_file(anno_file):
    data = open(anno_file, "rb").read()
    anno_dict = defaultdict(list)
    new_group = True
    groups = []
    cur = []
    for i in range(0, len(data), 8):
        x = unpack_u64le(data[i : i + 8])
        if x == MAX_U64:
            groups.append(cur)
            cur = []
        else:
            cur.append(x)

    for group in groups:
        path_id = group.pop(0)
        trips = []
        for i in range(0, len(group), 3):
            anno_dict[path_id].append((group[i], group[i + 1], group[i + 2]))

    for v in anno_dict.values():
        v.sort(key=lambda p: p[0])

    return anno_dict


# =====================================================
# =                   READ TRUE JACC VALUES           =
# =====================================================


def read_true_jacccards(jacc_file):
    return json.loads(open(jacc_file, "rb").read())
