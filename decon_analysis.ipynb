{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "990b5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contam_stats_dir = \"./my_stats\"\n",
    "eval_stats_path = \"eval_stats.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472d7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc0542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 217 evaluation datasets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_name</th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>passages</th>\n",
       "      <th>min_q_len</th>\n",
       "      <th>avg_q_len</th>\n",
       "      <th>max_q_len</th>\n",
       "      <th>min_a_len</th>\n",
       "      <th>avg_a_len</th>\n",
       "      <th>max_a_len</th>\n",
       "      <th>min_p_len</th>\n",
       "      <th>avg_p_len</th>\n",
       "      <th>max_p_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agi_eval_aqua_rat</td>\n",
       "      <td>1524</td>\n",
       "      <td>1524</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>192</td>\n",
       "      <td>491</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>830.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agi_eval_gaokao_english</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>1224</td>\n",
       "      <td>23</td>\n",
       "      <td>59</td>\n",
       "      <td>162</td>\n",
       "      <td>7.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>4047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agi_eval_logiqa_en</td>\n",
       "      <td>2604</td>\n",
       "      <td>2604</td>\n",
       "      <td>2604</td>\n",
       "      <td>35</td>\n",
       "      <td>86</td>\n",
       "      <td>231</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1004.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agi_eval_lsat_ar</td>\n",
       "      <td>1150</td>\n",
       "      <td>1150</td>\n",
       "      <td>1150</td>\n",
       "      <td>21</td>\n",
       "      <td>98</td>\n",
       "      <td>283</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agi_eval_lsat_lr</td>\n",
       "      <td>2550</td>\n",
       "      <td>2550</td>\n",
       "      <td>2550</td>\n",
       "      <td>24</td>\n",
       "      <td>95</td>\n",
       "      <td>311</td>\n",
       "      <td>24.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>winogrande</td>\n",
       "      <td>86864</td>\n",
       "      <td>83330</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>99</td>\n",
       "      <td>190</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>xstest</td>\n",
       "      <td>450</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>zebra_logic_grid</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>1223</td>\n",
       "      <td>2946</td>\n",
       "      <td>92.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>zebra_logic_mc</td>\n",
       "      <td>13242</td>\n",
       "      <td>13242</td>\n",
       "      <td>13242</td>\n",
       "      <td>47</td>\n",
       "      <td>51</td>\n",
       "      <td>57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>2946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>zero_scrolls_qasper</td>\n",
       "      <td>528</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8624</td>\n",
       "      <td>23136</td>\n",
       "      <td>137220</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   eval_name  questions  answers  passages  min_q_len  \\\n",
       "0          agi_eval_aqua_rat       1524     1524         0         12   \n",
       "1    agi_eval_gaokao_english       1224     1224      1224         23   \n",
       "2         agi_eval_logiqa_en       2604     2604      2604         35   \n",
       "3           agi_eval_lsat_ar       1150     1150      1150         21   \n",
       "4           agi_eval_lsat_lr       2550     2550      2550         24   \n",
       "..                       ...        ...      ...       ...        ...   \n",
       "212               winogrande      86864    83330         0         58   \n",
       "213                   xstest        450      450         0         12   \n",
       "214         zebra_logic_grid       1000     1000         0        394   \n",
       "215           zebra_logic_mc      13242    13242     13242         47   \n",
       "216      zero_scrolls_qasper        528       28         0       8624   \n",
       "\n",
       "     avg_q_len  max_q_len  min_a_len  avg_a_len  max_a_len  min_p_len  \\\n",
       "0          192        491        4.0       39.0      830.0        NaN   \n",
       "1           59        162        7.0       36.0      113.0      307.0   \n",
       "2           86        231        4.0       90.0      499.0       44.0   \n",
       "3           98        283        4.0       40.0      189.0      449.0   \n",
       "4           95        311       24.0      123.0      401.0      108.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "212         99        190        2.0        6.0       31.0        NaN   \n",
       "213         44         99        4.0        5.0        6.0        NaN   \n",
       "214       1223       2946       92.0      268.0      601.0        NaN   \n",
       "215         51         57        3.0        6.0       19.0      394.0   \n",
       "216      23136     137220        2.0       80.0      236.0        NaN   \n",
       "\n",
       "     avg_p_len  max_p_len  \n",
       "0          NaN        NaN  \n",
       "1       1808.0     4047.0  \n",
       "2        407.0     1004.0  \n",
       "3        593.0      771.0  \n",
       "4        387.0      797.0  \n",
       "..         ...        ...  \n",
       "212        NaN        NaN  \n",
       "213        NaN        NaN  \n",
       "214        NaN        NaN  \n",
       "215     1531.0     2946.0  \n",
       "216        NaN        NaN  \n",
       "\n",
       "[217 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load eval stats\n",
    "eval_stats = pd.read_csv(eval_stats_path)\n",
    "print(f\"Loaded {len(eval_stats)} evaluation datasets\")\n",
    "eval_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1624d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contamination Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training_docs_contaminated</td>\n",
       "      <td>600601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_contamination_instances</td>\n",
       "      <td>1626141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unique_eval_instances</td>\n",
       "      <td>350487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          metric    value\n",
       "0     training_docs_contaminated   600601\n",
       "1  total_contamination_instances  1626141\n",
       "2          unique_eval_instances   350487"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load contamination summary\n",
    "summary = pd.read_csv(f\"{contam_stats_dir}/summary.csv\")\n",
    "print(\"Contamination Summary:\")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "081c39c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training documents contaminated across 108 eval suites\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_suite</th>\n",
       "      <th>training_docs_contaminated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squad_v2</td>\n",
       "      <td>213312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>squad</td>\n",
       "      <td>188275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gsm8k</td>\n",
       "      <td>120644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drop</td>\n",
       "      <td>72176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trivia_qa</td>\n",
       "      <td>69218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jeopardy</td>\n",
       "      <td>29693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hendrycks_math_algebra</td>\n",
       "      <td>9640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hendrycks_math_intermediate_algebra</td>\n",
       "      <td>9303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hellaswag</td>\n",
       "      <td>7949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hendrycks_math_prealgebra</td>\n",
       "      <td>6319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            eval_suite  training_docs_contaminated\n",
       "0                             squad_v2                      213312\n",
       "1                                squad                      188275\n",
       "2                                gsm8k                      120644\n",
       "3                                 drop                       72176\n",
       "4                            trivia_qa                       69218\n",
       "5                             jeopardy                       29693\n",
       "6               hendrycks_math_algebra                        9640\n",
       "7  hendrycks_math_intermediate_algebra                        9303\n",
       "8                            hellaswag                        7949\n",
       "9            hendrycks_math_prealgebra                        6319"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training docs contaminated by suite\n",
    "training_docs_by_suite = pd.read_csv(f\"{contam_stats_dir}/training_docs_by_suite.csv\")\n",
    "print(f\"Training documents contaminated across {len(training_docs_by_suite)} eval suites\")\n",
    "training_docs_by_suite.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e75972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique eval instances found across 108 suites\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_suite</th>\n",
       "      <th>unique_eval_instances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squad_v2</td>\n",
       "      <td>117371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>squad</td>\n",
       "      <td>81718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drop</td>\n",
       "      <td>58140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trivia_qa</td>\n",
       "      <td>24606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jeopardy</td>\n",
       "      <td>11651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  eval_suite  unique_eval_instances\n",
       "0   squad_v2                 117371\n",
       "1      squad                  81718\n",
       "2       drop                  58140\n",
       "3  trivia_qa                  24606\n",
       "4   jeopardy                  11651"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load eval instances contaminated by suite\n",
    "eval_instances_by_suite = pd.read_csv(f\"{contam_stats_dir}/eval_instances_by_suite.csv\")\n",
    "print(f\"Unique eval instances found across {len(eval_instances_by_suite)} suites\")\n",
    "eval_instances_by_suite.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b806da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram Match Distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min_matches</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_matches</td>\n",
       "      <td>12442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>median_matches</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_matches</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>match_range</td>\n",
       "      <td>contamination_instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-5</td>\n",
       "      <td>184855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6-10</td>\n",
       "      <td>517583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11-20</td>\n",
       "      <td>460863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21-50</td>\n",
       "      <td>336295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51-100</td>\n",
       "      <td>103200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101-200</td>\n",
       "      <td>12525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>201-500</td>\n",
       "      <td>7522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>500+</td>\n",
       "      <td>3298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         statistic                    value\n",
       "0      min_matches                        1\n",
       "1      max_matches                    12442\n",
       "2   median_matches                       12\n",
       "3      avg_matches                     24.0\n",
       "4      match_range  contamination_instances\n",
       "5              1-5                   184855\n",
       "6             6-10                   517583\n",
       "7            11-20                   460863\n",
       "8            21-50                   336295\n",
       "9           51-100                   103200\n",
       "10         101-200                    12525\n",
       "11         201-500                     7522\n",
       "12            500+                     3298"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load n-gram distribution\n",
    "ngram_dist = pd.read_csv(f\"{contam_stats_dir}/ngram_distribution.csv\")\n",
    "print(\"N-gram Match Distribution:\")\n",
    "ngram_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a2bdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADED DATASETS SUMMARY\n",
      "============================================================\n",
      "\n",
      "1. Eval Stats: 217 evaluation datasets\n",
      "2. Contamination Summary: 3 metrics\n",
      "3. Training Docs by Suite: 108 eval suites\n",
      "4. Eval Instances by Suite: 108 eval suites\n",
      "5. N-gram Distribution: 13 rows\n",
      "\n",
      "All CSV files loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Summary of loaded data\n",
    "print(\"=\"*60)\n",
    "print(\"LOADED DATASETS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. Eval Stats: {len(eval_stats)} evaluation datasets\")\n",
    "print(f\"2. Contamination Summary: {len(summary)} metrics\")\n",
    "print(f\"3. Training Docs by Suite: {len(training_docs_by_suite)} eval suites\")\n",
    "print(f\"4. Eval Instances by Suite: {len(eval_instances_by_suite)} eval suites\")\n",
    "print(f\"5. N-gram Distribution: {len(ngram_dist)} rows\")\n",
    "print(\"\\nAll CSV files loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf71b928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of eval instances contaminated by suite (top 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_suite</th>\n",
       "      <th>unique_eval_instances</th>\n",
       "      <th>questions</th>\n",
       "      <th>percent_contaminated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>bbh_causal_judgement</td>\n",
       "      <td>181</td>\n",
       "      <td>187.0</td>\n",
       "      <td>96.791444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gsm8k</td>\n",
       "      <td>7472</td>\n",
       "      <td>8792.0</td>\n",
       "      <td>84.986351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>squad</td>\n",
       "      <td>81718</td>\n",
       "      <td>98169.0</td>\n",
       "      <td>83.242164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squad_v2</td>\n",
       "      <td>117371</td>\n",
       "      <td>142192.0</td>\n",
       "      <td>82.544025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>tulu3_do_anything_now</td>\n",
       "      <td>219</td>\n",
       "      <td>300.0</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drop</td>\n",
       "      <td>58140</td>\n",
       "      <td>86946.0</td>\n",
       "      <td>66.869091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gpqa_extended</td>\n",
       "      <td>311</td>\n",
       "      <td>546.0</td>\n",
       "      <td>56.959707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hendrycks_math_geometry</td>\n",
       "      <td>732</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>54.262417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hendrycks_math_intermediate_algebra</td>\n",
       "      <td>1188</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>54.049136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hendrycks_math_precalculus</td>\n",
       "      <td>666</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>51.547988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gpqa_main</td>\n",
       "      <td>230</td>\n",
       "      <td>448.0</td>\n",
       "      <td>51.339286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>deepseek_leetcode</td>\n",
       "      <td>85</td>\n",
       "      <td>180.0</td>\n",
       "      <td>47.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>math_500</td>\n",
       "      <td>222</td>\n",
       "      <td>500.0</td>\n",
       "      <td>44.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hendrycks_math_counting_and_probability</td>\n",
       "      <td>547</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>43.935743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hendrycks_math_number_theory</td>\n",
       "      <td>609</td>\n",
       "      <td>1409.0</td>\n",
       "      <td>43.222143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hendrycks_math_algebra</td>\n",
       "      <td>1177</td>\n",
       "      <td>2931.0</td>\n",
       "      <td>40.156943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>agi_eval_sat_en</td>\n",
       "      <td>82</td>\n",
       "      <td>206.0</td>\n",
       "      <td>39.805825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hendrycks_math_prealgebra</td>\n",
       "      <td>727</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>35.019268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>agi_eval_math</td>\n",
       "      <td>573</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>28.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>livecodebench</td>\n",
       "      <td>273</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>25.876777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>agi_eval_logiqa_en</td>\n",
       "      <td>552</td>\n",
       "      <td>2604.0</td>\n",
       "      <td>21.198157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ifbench_multiturn_constraints</td>\n",
       "      <td>265</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>19.105984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>agi_eval_lsat_rc</td>\n",
       "      <td>248</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>18.438662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>agi_eval_lsat_lr</td>\n",
       "      <td>463</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>18.156863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ifbench_multiturn_ifeval</td>\n",
       "      <td>320</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>18.038331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>agi_eval_lsat_ar</td>\n",
       "      <td>202</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>17.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>multipl_e_humaneval_js</td>\n",
       "      <td>26</td>\n",
       "      <td>161.0</td>\n",
       "      <td>16.149068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>aimo_validation</td>\n",
       "      <td>14</td>\n",
       "      <td>90.0</td>\n",
       "      <td>15.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ai2_arc_challenge</td>\n",
       "      <td>1527</td>\n",
       "      <td>10357.0</td>\n",
       "      <td>14.743652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trivia_qa</td>\n",
       "      <td>24606</td>\n",
       "      <td>173538.0</td>\n",
       "      <td>14.179027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 eval_suite  unique_eval_instances  questions  \\\n",
       "46                     bbh_causal_judgement                    181      187.0   \n",
       "5                                     gsm8k                   7472     8792.0   \n",
       "1                                     squad                  81718    98169.0   \n",
       "0                                  squad_v2                 117371   142192.0   \n",
       "44                    tulu3_do_anything_now                    219      300.0   \n",
       "2                                      drop                  58140    86946.0   \n",
       "34                            gpqa_extended                    311      546.0   \n",
       "19                  hendrycks_math_geometry                    732     1349.0   \n",
       "14      hendrycks_math_intermediate_algebra                   1188     2198.0   \n",
       "21               hendrycks_math_precalculus                    666     1292.0   \n",
       "41                                gpqa_main                    230      448.0   \n",
       "53                        deepseek_leetcode                     85      180.0   \n",
       "43                                 math_500                    222      500.0   \n",
       "27  hendrycks_math_counting_and_probability                    547     1245.0   \n",
       "23             hendrycks_math_number_theory                    609     1409.0   \n",
       "15                   hendrycks_math_algebra                   1177     2931.0   \n",
       "55                          agi_eval_sat_en                     82      206.0   \n",
       "20                hendrycks_math_prealgebra                    727     2076.0   \n",
       "24                            agi_eval_math                    573     2000.0   \n",
       "36                            livecodebench                    273     1055.0   \n",
       "26                       agi_eval_logiqa_en                    552     2604.0   \n",
       "38            ifbench_multiturn_constraints                    265     1387.0   \n",
       "40                         agi_eval_lsat_rc                    248     1345.0   \n",
       "29                         agi_eval_lsat_lr                    463     2550.0   \n",
       "33                 ifbench_multiturn_ifeval                    320     1774.0   \n",
       "45                         agi_eval_lsat_ar                    202     1150.0   \n",
       "68                   multipl_e_humaneval_js                     26      161.0   \n",
       "74                          aimo_validation                     14       90.0   \n",
       "12                        ai2_arc_challenge                   1527    10357.0   \n",
       "3                                 trivia_qa                  24606   173538.0   \n",
       "\n",
       "    percent_contaminated  \n",
       "46             96.791444  \n",
       "5              84.986351  \n",
       "1              83.242164  \n",
       "0              82.544025  \n",
       "44             73.000000  \n",
       "2              66.869091  \n",
       "34             56.959707  \n",
       "19             54.262417  \n",
       "14             54.049136  \n",
       "21             51.547988  \n",
       "41             51.339286  \n",
       "53             47.222222  \n",
       "43             44.400000  \n",
       "27             43.935743  \n",
       "23             43.222143  \n",
       "15             40.156943  \n",
       "55             39.805825  \n",
       "20             35.019268  \n",
       "24             28.650000  \n",
       "36             25.876777  \n",
       "26             21.198157  \n",
       "38             19.105984  \n",
       "40             18.438662  \n",
       "29             18.156863  \n",
       "33             18.038331  \n",
       "45             17.565217  \n",
       "68             16.149068  \n",
       "74             15.555556  \n",
       "12             14.743652  \n",
       "3              14.179027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate percent of eval instances contaminated per suite\n",
    "# Merge eval_instances_by_suite with eval_stats to get the total questions for each suite\n",
    "# The column in eval_stats for suite names is 'eval_name', and 'questions' is the total per task\n",
    "merged = pd.merge(\n",
    "    eval_instances_by_suite,\n",
    "    eval_stats[['eval_name', 'questions']],\n",
    "    left_on='eval_suite',\n",
    "    right_on='eval_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Compute the percentage ratio\n",
    "merged['percent_contaminated'] = merged['unique_eval_instances'] / merged['questions'] * 100\n",
    "\n",
    "# Sort by ratio descending, show top 10\n",
    "pct_table = merged[['eval_suite', 'unique_eval_instances', 'questions', 'percent_contaminated']].sort_values(\n",
    "    'percent_contaminated', ascending=False\n",
    ")\n",
    "print(\"Percent of eval instances contaminated by suite (top 10):\")\n",
    "display(pct_table.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1d1f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row for eval_suite == 'drop_mc':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_suite</th>\n",
       "      <th>unique_eval_instances</th>\n",
       "      <th>questions</th>\n",
       "      <th>percent_contaminated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>drop_mc</td>\n",
       "      <td>130</td>\n",
       "      <td>6352.0</td>\n",
       "      <td>2.046599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_suite  unique_eval_instances  questions  percent_contaminated\n",
       "51    drop_mc                    130     6352.0              2.046599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the row where eval_suite is \"drop_mc\" in pct_table\n",
    "drop_mc_row = pct_table[pct_table['eval_suite'] == \"drop_mc\"]\n",
    "print(\"Row for eval_suite == 'drop_mc':\")\n",
    "display(drop_mc_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e67b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
